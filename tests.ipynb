{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\anaconda3\\envs\\RL\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 2 2] [2 1 3 2 5 2]\n",
      "['red', 'red', 'blue', 'blue', 'green', 'green']\n",
      "{0: '0: N. America (2)', 1: '1: S. America (1)', 2: '2: Europe (3)', 3: '3: Africa (2)', 4: '4: Asia (5)', 5: '5: Oceania (2)'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.game import *\n",
    "from utils.agent import *\n",
    "from utils.world import *\n",
    "from utils.viz import *\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "map_graph = np.array([\n",
    "    [0, 1, 1, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0, 0],\n",
    "    [1, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 1, 0]\n",
    "])\n",
    "G = nx.from_numpy_array(map_graph)\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Nb player\n",
    "nb_player = 3\n",
    "\n",
    "# Vector of presence on the map\n",
    "# P[i, j] = #troops of player i in zone j\n",
    "presence_map_start = np.array([\n",
    "    [2, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 3, 2, 0, 0],\n",
    "    [0, 0, 0, 0, 5, 2]\n",
    "])\n",
    "\n",
    "layout = {0: np.array([0.5, 0.5]),\n",
    "           1: np.array([0.5, 0.3]),\n",
    "           2: np.array([0.5, 0.7]),\n",
    "           3: np.array([0.7, 0.5]),\n",
    "           4: np.array([0.3, 0.5]),\n",
    "           5: np.array([0.3, 0.3])\n",
    "           }\n",
    "\n",
    "countries = {0 : \"N. America\",\n",
    "            1 : \"S. America\",\n",
    "            2 : \"Europe\",\n",
    "            3 : \"Africa\",\n",
    "            4 : \"Asia\",\n",
    "            5 : \"Oceania\"\n",
    "            }\n",
    "\n",
    "owner = np.argmax(presence_map_start, axis=0)\n",
    "troops = np.max(presence_map_start, axis=0)\n",
    "\n",
    "colors = {0: 'red', 1: 'blue', 2: 'green'}\n",
    "colors = [colors[i] for i in owner]\n",
    "\n",
    "\n",
    "labels = {i:f\"{i}: {countries[i]} ({troops[i]})\" for i in range(map_graph.shape[0])}\n",
    "\n",
    "print(owner, troops)\n",
    "print(colors)\n",
    "print(labels)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.margins(x=0.2)\n",
    "G = nx.from_numpy_array(map_graph)\n",
    "label_options = {\"ec\": \"k\", \"fc\": \"white\", \"alpha\": 0.3}\n",
    "nx.draw(G, layout, node_color=colors, labels=labels, bbox=label_options)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the game as if the NaiveAgent was playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence map:\n",
      " [[2 1 0 0 0 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Player 0 territories:  [0, 1]\n",
      "Player 0 presence map:  [ 2  1 -3 -2 -5 -2]\n",
      "Reinforcements for player 0:  6\n",
      "Chosen territory:  0\n",
      "Presence map after deployment:\n",
      " [[8 1 0 0 0 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Possible attacks:  [(0, 2), (0, 4)]\n",
      "Chosen attack:  (0, 2)  ; player attacked:  1\n",
      "Presence map after attack:\n",
      " [[2 1 6 0 0 0]\n",
      " [0 0 0 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Available fortifications:  [(0, 1), (0, 2), (2, 0), (2, 1)]\n",
      "Chosen fortification:  (0, 1)\n",
      "Presence map after fortification:\n",
      " [[1 2 6 0 0 0]\n",
      " [0 0 0 2 0 0]\n",
      " [0 0 0 0 5 2]]\n"
     ]
    }
   ],
   "source": [
    "naive_agent = NaiveAgent()\n",
    "\n",
    "# Start\n",
    "game = Game(map_graph=map_graph, presence_map=presence_map_start, nb_players=nb_player)\n",
    "print(\"Presence map:\\n\", game.world.presence_map)\n",
    "print(\"Player 0 territories: \", game.world.get_territories(0))\n",
    "\n",
    "player_presence_map = game.world.get_player_presence_map(p=0)\n",
    "print(\"Player 0 presence map: \", player_presence_map)\n",
    "\n",
    "# Reinforcements\n",
    "to_deploy = game.world.get_reinforcements(p=0)\n",
    "print(\"Reinforcements for player 0: \", to_deploy)\n",
    "\n",
    "# Deployment\n",
    "t = naive_agent.choose_deploy(to_deploy, player_presence_map)\n",
    "print(\"Chosen territory: \", t)\n",
    "game.world.deploy(p=0, t=t, n=to_deploy)\n",
    "print(\"Presence map after deployment:\\n\", game.world.presence_map)\n",
    "\n",
    "# Attack\n",
    "player_presence_map = game.world.get_player_presence_map(p=0)\n",
    "attacks = game.world.get_available_targets(p=0)\n",
    "print(\"Possible attacks: \", attacks)\n",
    "if len(attacks) > 0:\n",
    "    chosen_attack = naive_agent.choose_attack(attacks, player_presence_map)\n",
    "    player_attacked = game.world.get_owner(chosen_attack[1])\n",
    "    print(\"Chosen attack: \", chosen_attack, \" ; player attacked: \", player_attacked)\n",
    "    game.resolve_battle(player1=0, player2=player_attacked,\n",
    "                        t_orig=chosen_attack[0], t_dest=chosen_attack[1])\n",
    "    print(\"Presence map after attack:\\n\", game.world.presence_map)\n",
    "\n",
    "# Fortification\n",
    "player_presence_map = game.world.get_player_presence_map(p=0)\n",
    "available_fortifications = game.world.get_available_fortifications(p=0)\n",
    "print(\"Available fortifications: \", available_fortifications)\n",
    "if len(available_fortifications) > 0:\n",
    "    chosen_fortification = naive_agent.choose_fortify(available_fortifications, player_presence_map)\n",
    "    print(\"Chosen fortification: \", chosen_fortification)\n",
    "    game.world.fortify(p=0, t_orig=0, t_dest=1)\n",
    "    print(\"Presence map after fortification:\\n\", game.world.presence_map)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to run some turns with naive agents and save the maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start\n",
    "game = Game(map_graph=map_graph, presence_map=presence_map_start, nb_players=nb_player)\n",
    "game.agents = [RandomAgent() for _ in range(nb_player)]\n",
    "\n",
    "# Play some turns\n",
    "game.run_and_save()\n",
    "\n",
    "# Generate a gif and save it\n",
    "generate_gif(\"./images/\", \"./gifs/\", fps=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try reinforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DeployNet(nn.Module):\n",
    "    def __init__(self, nb_territories=6, hidden_size=16):\n",
    "        super(DeployNet, self).__init__()\n",
    "\n",
    "        self.input_fc = nn.Linear(nb_territories, hidden_size)\n",
    "        #self.output_fc = nn.Linear(hidden_size+1, nb_territories)\n",
    "        self.output_fc = nn.Linear(hidden_size, nb_territories)\n",
    "\n",
    "    def forward(self, reinforcements, player_presence_map):\n",
    "\n",
    "        # Find the possible actions (territories where the player has a presence)\n",
    "        possible_actions = (player_presence_map > 0)\n",
    "\n",
    "        # Apply a linear layer to the input\n",
    "        x = F.tanh(self.input_fc(player_presence_map))\n",
    "\n",
    "        # Concatenate the reinforcements to the output\n",
    "        #x = torch.cat((x, reinforcements), dim=0)\n",
    "\n",
    "        # Apply a linear layer to the output\n",
    "        x = F.tanh(self.output_fc(x))\n",
    "        \n",
    "        # Mask the impossible actions\n",
    "        x[~possible_actions] = -1000\n",
    "\n",
    "        # Softmax the output\n",
    "        actions_prob = F.softmax(x, dim=0)\n",
    "\n",
    "        return actions_prob\n",
    "\n",
    "class AttackFortifyNet(nn.Module):\n",
    "    def __init__(self, nb_territories=6, hidden_size=16):\n",
    "        super(AttackFortifyNet, self).__init__()\n",
    "\n",
    "        self.input_fc = nn.Linear(nb_territories, hidden_size)\n",
    "        self.torig_fc = nn.Linear(hidden_size, nb_territories)\n",
    "        self.tdest_fc = nn.Linear(hidden_size, nb_territories)\n",
    "\n",
    "    def forward(self, possible_actions, player_presence_map):\n",
    "\n",
    "        # Apply a linear layer to the input\n",
    "        x = F.tanh(self.input_fc(player_presence_map))\n",
    "\n",
    "        # Split the output into two vectors (one for t_orig, one for t_dest)\n",
    "        torig = F.tanh(self.torig_fc(x))\n",
    "        tdest = F.tanh(self.tdest_fc(x))\n",
    "        \n",
    "        # Build a matrix of output with a dot product\n",
    "        embedding_mat = torch.outer(torig, tdest)\n",
    "\n",
    "        mask = torch.zeros_like(embedding_mat)\n",
    "        for a in possible_actions:\n",
    "            mask[a[0], a[1]] = 1\n",
    "\n",
    "        # Put to zero all the positions that are not in possible_actions\n",
    "        embedding_mat = torch.where(mask==1, embedding_mat, torch.zeros_like(embedding_mat)-1000)\n",
    "            \n",
    "        # Flatten the matrix\n",
    "        embedding_mat = embedding_mat.flatten()\n",
    "\n",
    "        # Softmax the output\n",
    "        actions_prob = F.softmax(embedding_mat, dim=0)\n",
    "\n",
    "        return actions_prob\n",
    "\n",
    "class PolicyGradientAgent():\n",
    "    def __init__(self, nb_territories=6,\n",
    "                 learning_rate=0.01, gamma=0.99):\n",
    "\n",
    "        self.nb_territories = nb_territories\n",
    "\n",
    "        self.deploy_policy = DeployNet(nb_territories=nb_territories)\n",
    "        self.attack_policy = AttackFortifyNet(nb_territories=nb_territories)\n",
    "        self.fortify_policy = AttackFortifyNet(nb_territories=nb_territories)\n",
    "\n",
    "        self.deploy_optimizer = torch.optim.Adam(self.deploy_policy.parameters(), lr=learning_rate)\n",
    "        self.attack_optimizer = torch.optim.Adam(self.attack_policy.parameters(), lr=learning_rate)\n",
    "        self.fortify_optimizer = torch.optim.Adam(self.fortify_policy.parameters(), lr=learning_rate)\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def choose_deploy_prob(self, reinforcements, player_presence_map):\n",
    "        \"\"\"Returns the territories to deploy troops on\"\"\"\n",
    "\n",
    "        # Output of the deploy policy\n",
    "        deploy_log_prob = self.deploy_policy(reinforcements, player_presence_map)\n",
    "\n",
    "        # Sample an action\n",
    "        m = Categorical(deploy_log_prob)\n",
    "        action = m.sample()\n",
    "\n",
    "        return action.item(), m.log_prob(action)\n",
    "\n",
    "    def choose_attack_prob(self, attacks, player_presence_map):\n",
    "        \"\"\"Returns the territory to attack\"\"\"\n",
    "\n",
    "        # Output of the attack policy\n",
    "        attack_log_prob = self.attack_policy(attacks, player_presence_map)\n",
    "\n",
    "        # Sample an action\n",
    "        m = Categorical(attack_log_prob)\n",
    "        action = m.sample()\n",
    "\n",
    "        # Decode the action into a territory pair\n",
    "        t_orig = action // self.nb_territories\n",
    "        t_dest = (action % self.nb_territories)\n",
    "\n",
    "        return t_orig.item(), t_dest.item(), m.log_prob(action)\n",
    "\n",
    "    def choose_fortify_prob(self, possible_fortifications, player_presence_map):\n",
    "        \"\"\"Returns the territory to fortify at the end of the turn\"\"\"\n",
    "\n",
    "        # Output of the fortify policy\n",
    "        fortify_log_prob = self.fortify_policy(possible_fortifications, player_presence_map)\n",
    "\n",
    "        # Sample an action\n",
    "        m = Categorical(fortify_log_prob)\n",
    "        action = m.sample()\n",
    "\n",
    "        # Decode the action into a territory pair\n",
    "        t_orig = action // self.nb_territories\n",
    "        t_dest = (action % self.nb_territories)\n",
    "\n",
    "        return t_orig.item(), t_dest.item(), m.log_prob(action)\n",
    "\n",
    "    def choose_deploy(self, reinforcements, player_presence_map):\n",
    "        \"\"\"The greedy version of choose_deploy_prob\"\"\"\n",
    "\n",
    "        output = self.deploy_policy(reinforcements, player_presence_map)\n",
    "        probs = F.softmax(output, dim=0).cpu()\n",
    "\n",
    "        return torch.argmax(probs).item()\n",
    "\n",
    "    def choose_attack(self, attacks, player_presence_map):\n",
    "        \"\"\"The greedy version of choose_attack_prob\"\"\"\n",
    "\n",
    "        # Output of the attack policy\n",
    "        attack_log_prob = self.attack_policy(attacks, player_presence_map)\n",
    "\n",
    "        # Take the action with the highest probability\n",
    "        action = torch.argmax(attack_log_prob)\n",
    "\n",
    "        # Decode the action into a territory pair\n",
    "        t_orig = action // self.nb_territories\n",
    "        t_dest = (action % self.nb_territories)\n",
    "\n",
    "        return t_orig.item(), t_dest.item()\n",
    "\n",
    "    def choose_fortify(self, fortifications, player_presence_map):\n",
    "        \"\"\"The greedy version of choose_fortify_prob\"\"\"\n",
    "\n",
    "        # Output of the fortify policy\n",
    "        fortify_log_prob = self.fortify_policy(fortifications, player_presence_map)\n",
    "\n",
    "        # Take the action with the highest probability\n",
    "        action = torch.argmax(fortify_log_prob)\n",
    "\n",
    "        # Decode the action into a territory pair\n",
    "        t_orig = action // self.nb_territories\n",
    "        t_dest = (action % self.nb_territories)\n",
    "\n",
    "        return t_orig.item(), t_dest.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence map:\n",
      " [[2 1 0 0 0 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Player 0 territories:  [0, 1]\n",
      "Player 0 presence map:  tensor([ 2.,  1., -3., -2., -5., -2.])\n",
      "Reinforcements for player 0:  tensor([6])\n",
      "Chosen territory:  0  ; prob:  tensor(-1.5972, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after deployment:\n",
      " [[8 1 0 0 0 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Possible attacks:  [(0, 2), (0, 4)]\n",
      "Chosen attack:  0 4  ; player attacked:  2  ; prob:  tensor(-0.6183, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after attack:\n",
      " [[2 1 0 0 6 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 0 2]]\n",
      "Available fortifications:  [(0, 1), (0, 4), (4, 0)]\n",
      "Chosen fortification:  0 1  ; prob:  tensor(-1.3574, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after fortification:\n",
      " [[1 2 0 0 6 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Louis\\anaconda3\\envs\\RL\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "game = Game(map_graph=map_graph, presence_map=presence_map_start, nb_players=nb_player)\n",
    "game.agents = [PolicyGradientAgent(), RandomAgent(), RandomAgent()]\n",
    "\n",
    "test_agent = PolicyGradientAgent()\n",
    "\n",
    "print(\"Presence map:\\n\", game.world.presence_map)\n",
    "print(\"Player 0 territories: \", game.world.get_territories(0))\n",
    "\n",
    "player_presence_map = torch.tensor(game.world.get_player_presence_map(p=0)).float()\n",
    "print(\"Player 0 presence map: \", player_presence_map)\n",
    "\n",
    "# Reinforcements\n",
    "to_deploy = torch.tensor([game.world.get_reinforcements(p=0)])\n",
    "print(\"Reinforcements for player 0: \", to_deploy)\n",
    "\n",
    "# Deployment\n",
    "t, prob = test_agent.choose_deploy_prob(to_deploy, player_presence_map)\n",
    "print(\"Chosen territory: \", t, \" ; prob: \", prob)\n",
    "game.world.deploy(p=0, t=t, n=to_deploy)\n",
    "print(\"Presence map after deployment:\\n\", game.world.presence_map)\n",
    "\n",
    "# Attack\n",
    "player_presence_map = torch.tensor(game.world.get_player_presence_map(p=0)).float()\n",
    "attacks = game.world.get_available_targets(p=0)\n",
    "print(\"Possible attacks: \", attacks)\n",
    "if len(attacks) > 0:\n",
    "    t_orig, t_dest, prob = test_agent.choose_attack_prob(attacks, player_presence_map)\n",
    "    player_attacked = game.world.get_owner(t_dest)\n",
    "    print(\"Chosen attack: \", t_orig, t_dest, \" ; player attacked: \", player_attacked, \" ; prob: \", prob)\n",
    "    game.resolve_battle(player1=0, player2=player_attacked,\n",
    "                        t_orig=t_orig, t_dest=t_dest)\n",
    "    print(\"Presence map after attack:\\n\", game.world.presence_map)\n",
    "\n",
    "# Fortification\n",
    "player_presence_map = torch.tensor(game.world.get_player_presence_map(p=0)).float()\n",
    "available_fortifications = game.world.get_available_fortifications(p=0)\n",
    "print(\"Available fortifications: \", available_fortifications)\n",
    "if len(available_fortifications) > 0:\n",
    "    t_orig, t_dest, prob = test_agent.choose_fortify_prob(available_fortifications, player_presence_map)\n",
    "    print(\"Chosen fortification: \", t_orig, t_dest, \" ; prob: \", prob)\n",
    "    game.world.fortify(p=0, t_orig=t_orig, t_dest=t_dest)\n",
    "    print(\"Presence map after fortification:\\n\", game.world.presence_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence map:\n",
      " [[2 1 0 0 0 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Player  0  territories:  2\n",
      "Player 0 presence map:  tensor([ 2.,  1., -3., -2., -5., -2.])\n",
      "Reinforcements for player 0:  tensor([6])\n",
      "Chosen territory:  1  ; prob:  tensor(-0.5472, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after deployment:\n",
      " [[2 7 0 0 0 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Possible attacks:  [(0, 2), (1, 2), (0, 4)]\n",
      "Chosen attack:  0 4  ; player attacked:  2  ; prob:  tensor(-0.9211, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after attack:\n",
      " [[1 7 0 0 0 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Available fortifications:  [(1, 0)]\n",
      "Chosen fortification:  1 0  ; prob:  tensor(-1.1921e-07, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after fortification:\n",
      " [[7 1 0 0 0 0]\n",
      " [0 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Player  1  territories:  2\n",
      "Player  1\n",
      "Player 1 territories:  [2, 3]\n",
      "Player 1 presence map:  tensor([-7., -1.,  3.,  2., -5., -2.])\n",
      "Reinforcements for player 1:  tensor([6])\n",
      "Chosen territory:  2\n",
      "Presence map after deployment:\n",
      " [[7 1 0 0 0 0]\n",
      " [0 0 9 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Possible attacks:  [(3, 1), (2, 4), (2, 0), (2, 1)]\n",
      "Chosen attack:  2 0  ; player attacked:  0\n",
      "Presence map after attack:\n",
      " [[0 1 0 0 0 0]\n",
      " [6 0 3 2 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Available fortifications:  [(0, 2), (2, 0), (2, 3), (3, 2)]\n",
      "Chosen fortification:  3 2\n",
      "Presence map after fortification:\n",
      " [[0 1 0 0 0 0]\n",
      " [6 0 4 1 0 0]\n",
      " [0 0 0 0 5 2]]\n",
      "Player  2  territories:  2\n",
      "Player  2\n",
      "Player 2 territories:  [4, 5]\n",
      "Player 2 presence map:  tensor([-6., -1., -4., -1.,  5.,  2.])\n",
      "Reinforcements for player 2:  tensor([6])\n",
      "Chosen territory:  4\n",
      "Presence map after deployment:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 6  0  4  1  0  0]\n",
      " [ 0  0  0  0 11  2]]\n",
      "Possible attacks:  [(4, 0), (4, 2)]\n",
      "Chosen attack:  4 0  ; player attacked:  1\n",
      "Presence map after attack:\n",
      " [[0 1 0 0 0 0]\n",
      " [0 0 4 1 0 0]\n",
      " [6 0 0 0 5 2]]\n",
      "Available fortifications:  [(0, 4), (4, 0), (4, 5), (5, 4)]\n",
      "Chosen fortification:  5 4\n",
      "Presence map after fortification:\n",
      " [[0 1 0 0 0 0]\n",
      " [0 0 4 1 0 0]\n",
      " [6 0 0 0 6 1]]\n",
      "Player  0  territories:  1\n",
      "Player 0 presence map:  tensor([-6.,  1., -4., -1., -6., -1.])\n",
      "Reinforcements for player 0:  tensor([3])\n",
      "Chosen territory:  1  ; prob:  tensor(-1.1921e-07, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after deployment:\n",
      " [[0 4 0 0 0 0]\n",
      " [0 0 4 1 0 0]\n",
      " [6 0 0 0 6 1]]\n",
      "Possible attacks:  [(1, 0), (1, 2)]\n",
      "Chosen attack:  1 0  ; player attacked:  2  ; prob:  tensor(-0.6491, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after attack:\n",
      " [[0 1 0 0 0 0]\n",
      " [0 0 4 1 0 0]\n",
      " [6 0 0 0 6 1]]\n",
      "Available fortifications:  []\n",
      "Player  1  territories:  2\n",
      "Player  1\n",
      "Player 1 territories:  [2, 3]\n",
      "Player 1 presence map:  tensor([-6., -1.,  4.,  1., -6., -1.])\n",
      "Reinforcements for player 1:  tensor([6])\n",
      "Chosen territory:  2\n",
      "Presence map after deployment:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0 10  1  0  0]\n",
      " [ 6  0  0  0  6  1]]\n",
      "Possible attacks:  [(2, 4), (2, 0), (2, 1)]\n",
      "Chosen attack:  2 0  ; player attacked:  2\n",
      "Presence map after attack:\n",
      " [[0 1 0 0 0 0]\n",
      " [0 0 1 1 0 0]\n",
      " [6 0 0 0 6 1]]\n",
      "Available fortifications:  []\n",
      "Player  2  territories:  3\n",
      "Player  2\n",
      "Player 2 territories:  [0, 4, 5]\n",
      "Player 2 presence map:  tensor([ 6., -1., -1., -1.,  6.,  1.])\n",
      "Reinforcements for player 2:  tensor([9])\n",
      "Chosen territory:  5\n",
      "Presence map after deployment:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  1  1  0  0]\n",
      " [ 6  0  0  0  6 10]]\n",
      "Possible attacks:  [(0, 1), (0, 2), (4, 2)]\n",
      "Chosen attack:  4 2  ; player attacked:  1\n",
      "Presence map after attack:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 6  0  5  0  1 10]]\n",
      "Available fortifications:  [(0, 2), (0, 4), (2, 0), (2, 4), (5, 4)]\n",
      "Chosen fortification:  0 4\n",
      "Presence map after fortification:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 1  0  5  0  6 10]]\n",
      "Player  0  territories:  1\n",
      "Player 0 presence map:  tensor([ -1.,   1.,  -5.,  -1.,  -6., -10.])\n",
      "Reinforcements for player 0:  tensor([3])\n",
      "Chosen territory:  1  ; prob:  tensor(-1.1921e-07, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after deployment:\n",
      " [[ 0  4  0  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 1  0  5  0  6 10]]\n",
      "Possible attacks:  [(1, 0), (1, 2)]\n",
      "Chosen attack:  1 2  ; player attacked:  2  ; prob:  tensor(-0.8126, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after attack:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 1  0  5  0  6 10]]\n",
      "Available fortifications:  []\n",
      "Player  1  territories:  1\n",
      "Player  1\n",
      "Player 1 territories:  [3]\n",
      "Player 1 presence map:  tensor([ -1.,  -1.,  -5.,   1.,  -6., -10.])\n",
      "Reinforcements for player 1:  tensor([3])\n",
      "Chosen territory:  3\n",
      "Presence map after deployment:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  0  4  0  0]\n",
      " [ 1  0  5  0  6 10]]\n",
      "Possible attacks:  [(3, 1), (3, 2)]\n",
      "Chosen attack:  3 2  ; player attacked:  2\n",
      "Presence map after attack:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 1  0  5  0  6 10]]\n",
      "Available fortifications:  []\n",
      "Player  2  territories:  4\n",
      "Player  2\n",
      "Player 2 territories:  [0, 2, 4, 5]\n",
      "Player 2 presence map:  tensor([ 1., -1.,  5., -1.,  6., 10.])\n",
      "Reinforcements for player 2:  tensor([12])\n",
      "Chosen territory:  2\n",
      "Presence map after deployment:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 1  0 17  0  6 10]]\n",
      "Possible attacks:  [(2, 3), (2, 1)]\n",
      "Chosen attack:  2 3  ; player attacked:  1\n",
      "Presence map after attack:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1  0 11  6  6 10]]\n",
      "Available fortifications:  [(2, 0), (2, 3), (2, 4), (3, 2), (4, 0), (4, 2), (4, 5), (5, 4)]\n",
      "Chosen fortification:  5 4\n",
      "Presence map after fortification:\n",
      " [[ 0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1  0 11  6 15  1]]\n",
      "Player  0  territories:  1\n",
      "Player 0 presence map:  tensor([ -1.,   1., -11.,  -6., -15.,  -1.])\n",
      "Reinforcements for player 0:  tensor([3])\n",
      "Chosen territory:  1  ; prob:  tensor(-1.1921e-07, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after deployment:\n",
      " [[ 0  4  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 1  0 11  6 15  1]]\n",
      "Possible attacks:  [(1, 0), (1, 2)]\n",
      "Chosen attack:  1 0  ; player attacked:  2  ; prob:  tensor(-0.6955, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after attack:\n",
      " [[ 3  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0 11  6 15  1]]\n",
      "Available fortifications:  [(0, 1)]\n",
      "Chosen fortification:  0 1  ; prob:  tensor(-1.1921e-07, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after fortification:\n",
      " [[ 1  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0 11  6 15  1]]\n",
      "Player  1  territories:  0\n",
      "Player  1  has lost the game\n",
      "Player  2  territories:  4\n",
      "Player  2\n",
      "Player 2 territories:  [2, 3, 4, 5]\n",
      "Player 2 presence map:  tensor([-1., -3., 11.,  6., 15.,  1.])\n",
      "Reinforcements for player 2:  tensor([12])\n",
      "Chosen territory:  4\n",
      "Presence map after deployment:\n",
      " [[ 1  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  0 11  6 27  1]]\n",
      "Possible attacks:  [(3, 1), (4, 0), (2, 0), (2, 1)]\n",
      "Chosen attack:  2 1  ; player attacked:  0\n",
      "Presence map after attack:\n",
      " [[ 1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  6  5  6 27  1]]\n",
      "Available fortifications:  [(1, 2), (2, 1), (2, 3), (2, 4), (3, 1), (3, 2), (4, 2), (4, 5)]\n",
      "Chosen fortification:  2 3\n",
      "Presence map after fortification:\n",
      " [[ 1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  6  1 10 27  1]]\n",
      "Player  0  territories:  1\n",
      "Player 0 presence map:  tensor([  1.,  -6.,  -1., -10., -27.,  -1.])\n",
      "Reinforcements for player 0:  tensor([3])\n",
      "Chosen territory:  0  ; prob:  tensor(-1.1921e-07, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after deployment:\n",
      " [[ 4  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  6  1 10 27  1]]\n",
      "Possible attacks:  [(0, 1), (0, 2), (0, 4)]\n",
      "Chosen attack:  0 4  ; player attacked:  2  ; prob:  tensor(-0.9011, grad_fn=<SqueezeBackward1>)\n",
      "Presence map after attack:\n",
      " [[ 1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0  6  1 10 27  1]]\n",
      "Available fortifications:  []\n",
      "Player  1  territories:  0\n",
      "Player  1  has lost the game\n",
      "Player  2  territories:  5\n",
      "Player  2\n",
      "Player 2 territories:  [1, 2, 3, 4, 5]\n",
      "Player 2 presence map:  tensor([-1.,  6.,  1., 10., 27.,  1.])\n",
      "Reinforcements for player 2:  tensor([15])\n",
      "Chosen territory:  1\n",
      "Presence map after deployment:\n",
      " [[ 1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 0 21  1 10 27  1]]\n",
      "Possible attacks:  [(1, 0), (4, 0)]\n",
      "Chosen attack:  1 0  ; player attacked:  0\n",
      "Presence map after attack:\n",
      " [[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [ 6 15  1 10 27  1]]\n",
      "Available fortifications:  [(0, 1), (0, 2), (0, 4), (1, 0), (1, 2), (3, 1), (3, 2), (4, 0), (4, 2), (4, 5)]\n",
      "Chosen fortification:  4 0\n",
      "Presence map after fortification:\n",
      " [[ 0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0]\n",
      " [32 15  1 10  1  1]]\n"
     ]
    }
   ],
   "source": [
    "game = Game(map_graph=map_graph, presence_map=presence_map_start, nb_players=nb_player)\n",
    "game.agents = [PolicyGradientAgent(), RandomAgent(), RandomAgent()]\n",
    "\n",
    "print(\"Presence map:\\n\", game.world.presence_map)\n",
    "for j in range(5):\n",
    "    for i in range(3):\n",
    "        print(\"Player \", i, \" territories: \", len(game.world.get_territories(i)))\n",
    "        if len(game.world.get_territories(i)) > 0:\n",
    "            if i == 0:\n",
    "                player_presence_map = torch.tensor(game.world.get_player_presence_map(p=i)).float()\n",
    "                print(\"Player 0 presence map: \", player_presence_map)\n",
    "\n",
    "                # Reinforcements\n",
    "                to_deploy = torch.tensor([game.world.get_reinforcements(p=i)])\n",
    "                print(\"Reinforcements for player 0: \", to_deploy)\n",
    "\n",
    "                # Deployment\n",
    "                t, prob = game.agents[i].choose_deploy_prob(to_deploy, player_presence_map)\n",
    "                print(\"Chosen territory: \", t, \" ; prob: \", prob)\n",
    "                game.world.deploy(p=i, t=t, n=to_deploy)\n",
    "                print(\"Presence map after deployment:\\n\", game.world.presence_map)\n",
    "\n",
    "                # Attack\n",
    "                player_presence_map = torch.tensor(game.world.get_player_presence_map(p=i)).float()\n",
    "                attacks = game.world.get_available_targets(p=0)\n",
    "                print(\"Possible attacks: \", attacks)\n",
    "                if len(attacks) > 0:\n",
    "                    t_orig, t_dest, prob = game.agents[i].choose_attack_prob(attacks, player_presence_map)\n",
    "                    player_attacked = game.world.get_owner(t_dest)\n",
    "                    print(\"Chosen attack: \", t_orig, t_dest, \" ; player attacked: \", player_attacked, \" ; prob: \", prob)\n",
    "                    game.resolve_battle(player1=i, player2=player_attacked,\n",
    "                                        t_orig=t_orig, t_dest=t_dest)\n",
    "                    print(\"Presence map after attack:\\n\", game.world.presence_map)\n",
    "\n",
    "                # Fortification\n",
    "                player_presence_map = torch.tensor(game.world.get_player_presence_map(p=0)).float()\n",
    "                available_fortifications = game.world.get_available_fortifications(p=0)\n",
    "                print(\"Available fortifications: \", available_fortifications)\n",
    "                if len(available_fortifications) > 0:\n",
    "                    t_orig, t_dest, prob = game.agents[i].choose_fortify_prob(available_fortifications, player_presence_map)\n",
    "                    print(\"Chosen fortification: \", t_orig, t_dest, \" ; prob: \", prob)\n",
    "                    game.world.fortify(p=i, t_orig=t_orig, t_dest=t_dest)\n",
    "                    print(\"Presence map after fortification:\\n\", game.world.presence_map)\n",
    "            \n",
    "            else:\n",
    "                print(\"Player \", i)        \n",
    "                print(f\"Player {i} territories: \", game.world.get_territories(i))\n",
    "\n",
    "                player_presence_map = torch.tensor(game.world.get_player_presence_map(p=i)).float()\n",
    "                print(f\"Player {i} presence map: \", player_presence_map)\n",
    "\n",
    "                # Reinforcements\n",
    "                to_deploy = torch.tensor([game.world.get_reinforcements(p=i)])\n",
    "                print(f\"Reinforcements for player {i}: \", to_deploy)\n",
    "\n",
    "                # Deployment\n",
    "                t = game.agents[i].choose_deploy(to_deploy, player_presence_map)\n",
    "                print(\"Chosen territory: \", t)\n",
    "                game.world.deploy(p=i, t=t, n=to_deploy)\n",
    "                print(\"Presence map after deployment:\\n\", game.world.presence_map)\n",
    "\n",
    "                # Attack\n",
    "                player_presence_map = torch.tensor(game.world.get_player_presence_map(p=i)).float()\n",
    "                attacks = game.world.get_available_targets(p=i)\n",
    "                print(\"Possible attacks: \", attacks)\n",
    "                if len(attacks) > 0:\n",
    "                    t_orig, t_dest = test_agent.choose_attack(attacks, player_presence_map)\n",
    "                    player_attacked = game.world.get_owner(t_dest)\n",
    "                    print(\"Chosen attack: \", t_orig, t_dest, \" ; player attacked: \", player_attacked)\n",
    "                    game.resolve_battle(player1=i, player2=player_attacked,\n",
    "                                        t_orig=t_orig, t_dest=t_dest)\n",
    "                    print(\"Presence map after attack:\\n\", game.world.presence_map)\n",
    "\n",
    "                # Fortification\n",
    "                player_presence_map = torch.tensor(game.world.get_player_presence_map(p=i)).float()\n",
    "                available_fortifications = game.world.get_available_fortifications(p=i)\n",
    "                print(\"Available fortifications: \", available_fortifications)\n",
    "                if len(available_fortifications) > 0:\n",
    "                    t_orig, t_dest = test_agent.choose_fortify(available_fortifications, player_presence_map)\n",
    "                    print(\"Chosen fortification: \", t_orig, t_dest)\n",
    "                    game.world.fortify(p=i, t_orig=t_orig, t_dest=t_dest)\n",
    "                    print(\"Presence map after fortification:\\n\", game.world.presence_map)\n",
    "\n",
    "        else:\n",
    "            print(\"Player \", i, \" has lost the game\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d00adc353c58f08ff45dce4b6452c66b8278e88650636a09adf77ca588d0aa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
